{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1029d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, AdamW, SGD\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c110ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        self.images = [image for image in os.listdir(image_dir) if image.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        name,ext=os.path.splitext(self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, f'{name}.png')\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        image = self.transform(image)\n",
    "        mask = self.transform(mask)\n",
    "        mask = (mask > 0.5).float()\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1536c277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(image_dir, mask_dir, batch_size=2, shuffle=True):\n",
    "    dataset=SegmentationDataset(image_dir, mask_dir)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "41b5366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.conv2d=nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channel, out_channel, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),       \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.conv2d(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.conv = DoubleConv(in_channel, out_channel)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        down = self.conv(x)      \n",
    "        pool = self.pool(down) \n",
    "        return down, pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "33b53e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampple(nn.Module):\n",
    "    def __init__(self,in_channel, out_channel):\n",
    "        super().__init__()\n",
    "        self.up_sam=nn.ConvTranspose2d(in_channel, in_channel//2, 2,2)\n",
    "        self.conv=DoubleConv(in_channel, out_channel)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1=self.up_sam(x1)\n",
    "        x=torch.cat([x1,x2],1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f20212a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self,in_channel, num_classes):\n",
    "        super().__init__()\n",
    "        self.down_con_1=DownSample(in_channel, 64)\n",
    "        self.down_con_2=DownSample(64, 128)\n",
    "        self.down_con_3=DownSample(128, 256)\n",
    "        self.down_con_4=DownSample(256, 512)\n",
    "\n",
    "        self.bottle_neck=DoubleConv(512,1024)\n",
    "        \n",
    "        self.up_con_1=UpSampple(1024, 512)\n",
    "        self.up_con_2=UpSampple(512, 256)\n",
    "        self.up_con_3=UpSampple(256, 128)\n",
    "        self.up_con_4=UpSampple(128, 64)\n",
    "        \n",
    "        self.out=nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        down1, p1=self.down_con_1(x)\n",
    "        down2, p2=self.down_con_2(p1)\n",
    "        down3, p3=self.down_con_3(p2)\n",
    "        down4, p4=self.down_con_4(p3)\n",
    "        \n",
    "        b=self.bottle_neck(p4)\n",
    "        \n",
    "        up1=self.up_con_1(b,down4)\n",
    "        up2=self.up_con_2(up1,down3)\n",
    "        up3=self.up_con_3(up2,down2)\n",
    "        up4=self.up_con_4(up3,down1)\n",
    "        \n",
    "        output= self.out(up4)\n",
    "        return output \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aa9924e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "  def __init__(self, smooth=1e-6):\n",
    "    super(DiceLoss, self).__init__()\n",
    "    self.smooth = smooth\n",
    "\n",
    "  def forward(self, inputs, targets):\n",
    "    inputs = inputs.view(-1) #Flatten\n",
    "    targets = targets.view(-1)\n",
    "\n",
    "    intersection = (inputs * targets).sum()\n",
    "    dice_score = (2. * intersection + self.smooth) / (inputs.sum() + targets.sum() + self.smooth)\n",
    "\n",
    "    return 1 - dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a9b32905",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEWithDiceLoss(nn.Module):\n",
    "  def __init__(self, smooth=1e-6):\n",
    "    super(BCEWithDiceLoss, self).__init__()\n",
    "    self.bce = nn.BCEWithLogitsLoss()\n",
    "    self.dice = DiceLoss(smooth)\n",
    "\n",
    "  def forward(self, inputs,targets):\n",
    "    bce_loss = self.bce(inputs,targets)\n",
    "    dice_loss = self.dice(inputs,targets)\n",
    "    return 0.5*bce_loss + dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d8eeb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, epochs=1, lr=0.0001, save_path=\"unet_model\", load_path=None):\n",
    "    if load_path is not None:\n",
    "        print(\"Loading from the weight directly\")\n",
    "        model.load_state_dict(torch.load(load_path, map_location=\"cpu\"))\n",
    "    criterion=BCEWithDiceLoss()\n",
    "    optimizer=AdamW(model.parameters() ,lr=lr)\n",
    "    for e in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss=0\n",
    "        \n",
    "        for img, mask in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output=model(img)\n",
    "            \n",
    "            loss=criterion(output, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss+=loss.item()\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch [{e+1}/{epochs}], Loss : {avg_loss:.4f}, LR : {lr}\")\n",
    "        \n",
    "    torch.save(model.state_dict(),f\"{save_path}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=get_dataloader(\"U-Net/Human-Segmentation-Dataset/Training_Images\", \"U-Net/Human-Segmentation-Dataset/Ground_Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f76430c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Unet(in_channel=3,num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "426dff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss : 1.1634, LR : 0.0001\n"
     ]
    }
   ],
   "source": [
    "train(model,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee51355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict(model_path, input_image_path):\n",
    "    model = Unet(in_channel=3, num_classes=1)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    image = Image.open(input_image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        output = torch.sigmoid(output)\n",
    "   \n",
    "    mask = output.squeeze(0).squeeze(0).cpu().numpy()\n",
    "    mask = (mask > 0.5).astype(np.uint8) * 255\n",
    "    mask_image = Image.fromarray(mask)\n",
    "\n",
    "    combined = Image.new(\"RGB\", (224 * 2, 224))\n",
    "    combined.paste(image.resize((224, 224)), (0, 0))\n",
    "    combined.paste(mask_image.convert(\"RGB\"), (224, 0))\n",
    "    combined.save(\"output.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7b6ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Prediction completed! Stats:\n",
      "  Image Preprocessing Time: 0.0000 seconds\n",
      "  Model Inference Time: 0.3965 seconds\n",
      "  Postprocessing Time: 0.0013 seconds\n",
      "  Total Prediction Time: 0.3978 seconds\n",
      "Prediction saved as output.jpg\n"
     ]
    }
   ],
   "source": [
    "predict(model_path=\"unet_model.pth\", input_image_path=\"U-Net/Human-Segmentation-Dataset/Training_Images/24.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
